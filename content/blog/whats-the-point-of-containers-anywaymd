---
path: /whats-the-point-of-containers-anyway
date: 2018-02-19T05:00:00.000Z
title: What's the Point of Containers Anyway?
description: ""
tags:
  - software engineering
  - DevOps
  - CI/CD
  - what's the point
image: /assets/1_kmaqpsinlcdankzwymk3gq.jpeg
---

Have you heard of Docker? Or maybe containers? If you've been in software the past few years, you probably have.

There also might be a chance that you have _no idea_ what these technologies are. Or you might know what they are, but have no clue what they are used for. Or worse - you might be at a company going through a "devops transformation" where you are being forced to use these technologies and no one can tell you _why_. 

The fact is that containers are an incredible technology that bring a lot of really cool benefits, but introduce some new challenges too. Deciding to use containers or Docker isn't one to be made lightly. Let's dive into the benefits and challenges of these technologes and find out whats the point behind them.

## What is a Container?

Containers in software are actually like a shipping container (hence the name Docker - which we will get to later). They are essentially a "mini-computer" encapsulated into a single file. These files are referred to as images. These images get executed by running them on container engines - also called container runtime engines. A running image is called the container.

To go a step deeper, a container allows a team to package software assests, dependencies, code runtimes, and other tools into the container image. The result is that instead of having to install those items onto servers individually or via a server management tool (think Ansible, Puppet, Vagrant). This makes the image _portable_ which is one of the top benefits of containers. 

But you might be thinking - doesn't the software need an operating system to run on? How does the application in the image know how to interact with the operting system? This is a great question!

For the purposes of this article, the answer is that containers take advantage of operating system level virtualization. The container engine abstracts the specific operations system away, but still allows system calls from the appliction to "pass through" to the OS. While that is simple in theory, a lot of interesting kernel abilities exist to provide proper isolation (keep containers separate from each other)and resource limits (keep containers from hogging all of the resouces from themselves) to keep running containers from stomping on each other.

For more details on the internals of how a container works and how the OS works to support it, check out this zine from Julie Evans.

## What is Docker?

So we know what a container is, but we still need a container engine or runtime. Where do you find one of those? 

Enter Docker. Docker was one of the first container engines in mid-2000s that really ushered in the feasibility of running containers. You can easily install it on most computers and boom - you can start running containers. 

If this is the case, why are containers and Docker separate? Well this is because techncially there are many more engines than just Docker. Docker just happens to be the most popular. Other companies are have created alternative engines that run within their own eco-systems to avoid paying additional costs to Docker to be the engine.

But this introduced a common issue that happens as new software is created: formatting issues. Each engine had their own format for specifying the specifics about a container, which meant you had to built a container specifically for the engine you were using. Thankfully, companies have moved towards an approved and consistent format to make any container image run on any engine. This adds to the portability of images, which is a critical feature for containers.

Going back to Docker, then, the core takeaway is that if you are building and running containers, you will likely be using Docker. Get familiar with it :)

## Why Are Containers Popular?

Ok, ok. We've talked about a few details of containers and engines, etc. But we still haven't answered this question: what are containers so popular? Why is everyone talking about them (and why is my manager telling me to use it even though they can't tell me why)?

In a nutshell, containers have become popular for three core reasons: 

* Portability
* Infrastructue as Code
* Simplicity

### Portability

Because of the container engine abstraction, containers are extremely portable. Instead of having to download an RPM or `.exe` files, add various configuration files, and make sure the right system packages are installed, you just download and run an image. Yes, you still need to download the container engine, but for the most part, everything is pretty easy after that. Even if your company is managing your own servers, you can create reasonable contracts that a systems team is responsible for keeping the server up-to-date and with the right container engine. Application teams simply need to build the right type of container and it can be run anywhere on your infrastructure.

Additionally, containers have increased portability because many cloud providers offer some form of "containers as a service". Part of the Cloud Native movement, the ability to tell a cloud provider "here is my container - run it" without having to worry about servers is a huge benefit for application developers. This, coupled, with standerized container image formats allows application teams to get closer and closer to a true "build it once; run everywhere" mentality. In fact, focsuing on building container images as an appliction team can be a hedge against vendor lock-in. While migrating between clouds is never easy, if you had containers vs say EC2 instances or huge Ansible playbooks, it might be easier.

### Scale Economics

The other reason for the popularization of containers - especially for managers and leadership - is that containers can provide better scale economics. Taking the example of a company that currently runs their own infrastuture, there is a large probability that application A and application B have different (and even conflicting!) system requirements. This means it is easier to give each team their own virtual machines.

But what if application B is really simple and lightweight? It doesn't need a _whole_ virtual machine to run. It could do with just a few CPU cycles and a little bit of RAM. Containers make this easy. Because the containers have proper isolation from each other, a single container engine could be running a Java EE server and a Node JS sever side by side. If a virtual machine world, this could get complicated since the system requirements could start to get gnarly.

### Simplicity

Pigg-backing off of the Portability aspect, running a container is much easier than setting up a virtual machine or installing a service on a computer. This is especially true for local development. Instead of installing `mysql`, `kafka` or something else, you can just install a container with all of the configuration, dependencies, etc. available. While it wouldn't be appriopriate for a production environment, for a local developer, it is quick and easy to type `docker run the-app` and have something running.

Additionally, because of the "just run it" mentality of containers, the configuration of most images is also simple. Many images come with pre-baked in configuration, with the ability to set additional or neccesary environement specific values via environment variables. While this sounds like a no-brainer, many applications before containers would be a slew of nested configuration files in different formats. Containers make this type of configuration and setup simple and promotes [convention > configuration](https://en.wikipedia.org/wiki/Convention_over_configuration).

## What's the Point?

The point of containers is really simple: containers help development teams ship code in a more portable and cost effective way. While that might not sound powerful, once you work on a team that users containers effectively, you will see that they can indeed be really powerful tools.  

However, tread carefully. Containers are not a walk in the park. For one thing, where do you put them? How do you version them? How do you debug a running container in production? 

Think critically about why containers would work for you. A starting point might be encouraging your team to use containers for local development tools such as a database, server, or even just an OpenAPI editor. Start trying to use tools like Docker or Podman to run containers locally and get comfortable using them. Nothing would be worse than trying to containerize your whole application if you aren't comfortable running and debugging containers in general.

Also, think in a step-wise fashion. Before throwing out your infrastructure and installing Kubernetes - start with just building an image for your application. Start pushing it up to an internal repository and asking teams that use your application to try running it on their own local machines. Get the hang of what it means to build and version your images in lock-step with your existing release stategy. If you can do all of that before trying to run your application in a cloud, you will be in great shape.

Happy coding!

